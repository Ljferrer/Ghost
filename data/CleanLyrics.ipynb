{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import tqdm\n",
    "import spacy\n",
    "\n",
    "from pathlib import Path\n",
    "from sqlitedict import SqliteDict\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78728 files\n"
     ]
    }
   ],
   "source": [
    "raw_lyrics_dir = Path('./rawLyrics/')\n",
    "raw_lyrics_files = sorted(list(raw_lyrics_dir.glob('*.json')))\n",
    "print(f'Found {len(raw_lyrics_files)} files')\n",
    "\n",
    "clean_lyrics_dir = Path('./cleanLyrics/')\n",
    "clean_lyrics_dir.mkdir(exist_ok=True) \n",
    "\n",
    "all_lyrics = Path('AllLyrics.sqlite')\n",
    "aly = SqliteDict(all_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricGeniusFormatter:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en')\n",
    "        self.nlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\n",
    "        self.tok = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def detect_lang(self, text: str):\n",
    "        doc = self.nlp(text)\n",
    "        return doc._.language\n",
    "\n",
    "    def format_lyrics(self, raw_lyrics_file: Path):\n",
    "\n",
    "        # Load song dict\n",
    "        with open(raw_lyrics_file, 'r') as rlf:\n",
    "            raw = json.loads(rlf.read())\n",
    "        raw_lyrics = str(raw['songs'][0]['lyrics'])\n",
    "\n",
    "        # Detect language\n",
    "        detect = self.detect_lang(raw_lyrics)\n",
    "        if 'en' not in detect['language'] or detect['score'] < 0.9:\n",
    "#             print(f'Not EN: {raw_lyrics_file}\\n')\n",
    "            return\n",
    "\n",
    "        # Copy fields\n",
    "        formatted = dict()\n",
    "        formatted['artist'] = raw['artist']\n",
    "        formatted['title'] = raw['songs'][0]['title']\n",
    "        formatted['year'] = raw['songs'][0]['year']\n",
    "        formatted['image'] = raw['songs'][0]['image']\n",
    "        formatted['raw_lyrics'] = raw_lyrics\n",
    "\n",
    "        # Clean lyrics\n",
    "        sections = list()\n",
    "        header_seed = '(\\n\\n(\\[.*|\\(.*\\)|\\{.*|[0-9].*|.*:\\n|[R-r]epeat.*))'\n",
    "        # For splitting by \\n\\n followed by\n",
    "        # [... , (...) , {... , int... , ...: , or (R/r)epeat...\n",
    "        raw_sections = re.split(header_seed, '\\n\\n' + raw_lyrics)   # Catch [Intro]\n",
    "        for raw_sect in raw_sections:\n",
    "            clean_seed = r'\\([^)].*\\)|\\[.*?\\]|\\(|\\)|\\[|\\]|:'\n",
    "            clean_sect = re.sub(clean_seed, '', raw_sect)        # Clean residual\n",
    "            split_sect = [l for l in clean_sect.split('\\n') if len(self.tok.tokenize(l))]\n",
    "            if len(split_sect) > 1:\n",
    "                sections.append(split_sect)\n",
    "\n",
    "        formatted['sections'] = sections\n",
    "\n",
    "        return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist :: 03 Greedo\n",
      "\n",
      "title :: 03 Purple Hearts\n",
      "\n",
      "year :: 2017-07-26\n",
      "\n",
      "image :: https://images.genius.com/6c258cf65eef13108dc10c3720ad2a25.1000x1000x1.jpg\n",
      "\n",
      "raw_lyrics :: [Intro]\n",
      "Three purple hearts\n",
      "Three purple hearts\n",
      "Three purple hearts\n",
      "\n",
      "[Verse]\n",
      "She ain't love me 'til she saw me shine\n",
      "Playin' with a nigga all this time\n",
      "You ain't love me 'til you saw me shine\n",
      "Playin' with a nigga all this time\n",
      "She wear a minute, now I'm on your mind\n",
      "Since I lost Lil Money I been on my grind\n",
      "Always been one hundred, never told her lies\n",
      "I can't let her go, I will never really know why\n",
      "Shay Shay you got my attention\n",
      "Sorry for times I went missing\n",
      "Have you heard 'bout whose lips I'm kissin'\n",
      "I understand why you keepin' your distance\n",
      "But I still love you\n",
      "And I never care who done fucked you\n",
      "Been in this game, I can't judge, wave it above you\n",
      "That's what these lames do\n",
      "Know I done played you so I can't blame you\n",
      "But why you so playful? don't make me hate you\n",
      "I never fake and act like you wasn't there when I had nothing at the bottom\n",
      "Now I'm at the top, that's why everything that you ever want, you know you got it\n",
      "Sucker for love, fuck with a thug\n",
      "She ain't leave when I was broke and I was strung out on them drugs\n",
      "Stored at nothin' but under three purple heart\n",
      "Stored at nothin' but under three purple heart\n",
      "Stored at nothin' but under three\n",
      "Stored at nothin' but under three\n",
      "Now she fuck with 03, purple hearts, yeah\n",
      "Stored at nothin' but under three purple heart\n",
      "\n",
      "\n",
      "\n",
      "sections\n",
      "\n",
      "Three purple hearts\n",
      "Three purple hearts\n",
      "Three purple hearts\n",
      "\n",
      "\n",
      "She ain't love me 'til she saw me shine\n",
      "Playin' with a nigga all this time\n",
      "You ain't love me 'til you saw me shine\n",
      "Playin' with a nigga all this time\n",
      "She wear a minute, now I'm on your mind\n",
      "Since I lost Lil Money I been on my grind\n",
      "Always been one hundred, never told her lies\n",
      "I can't let her go, I will never really know why\n",
      "Shay Shay you got my attention\n",
      "Sorry for times I went missing\n",
      "Have you heard 'bout whose lips I'm kissin'\n",
      "I understand why you keepin' your distance\n",
      "But I still love you\n",
      "And I never care who done fucked you\n",
      "Been in this game, I can't judge, wave it above you\n",
      "That's what these lames do\n",
      "Know I done played you so I can't blame you\n",
      "But why you so playful? don't make me hate you\n",
      "I never fake and act like you wasn't there when I had nothing at the bottom\n",
      "Now I'm at the top, that's why everything that you ever want, you know you got it\n",
      "Sucker for love, fuck with a thug\n",
      "She ain't leave when I was broke and I was strung out on them drugs\n",
      "Stored at nothin' but under three purple heart\n",
      "Stored at nothin' but under three purple heart\n",
      "Stored at nothin' but under three\n",
      "Stored at nothin' but under three\n",
      "Now she fuck with 03, purple hearts, yeah\n",
      "Stored at nothin' but under three purple heart\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "f = LyricGeniusFormatter()\n",
    "\n",
    "for i, rlf in enumerate(raw_lyrics_files):\n",
    "    formatted_song = f.format_lyrics(rlf)\n",
    "\n",
    "    # Verify visually\n",
    "    if i == 0:\n",
    "        for k, v in formatted_song.items():\n",
    "            if isinstance(v, list):\n",
    "                print(f'\\n\\n{k}\\n')\n",
    "                for s in v:\n",
    "                    for l in s:\n",
    "                        print(l)\n",
    "                    print('\\n')\n",
    "            else:\n",
    "                print(f'{k} :: {v}\\n')\n",
    "                pass\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "train_file = Path(f'./cleanLyrics/{n:02d}-train-base-uncased-78728.txt')\n",
    "dev_file = Path(f'./cleanLyrics/{n:02d}-dev-base-uncased-78728.txt')\n",
    "test_file = Path(f'./cleanLyrics/{n:02d}-test-base-uncased-78728.txt')\n",
    "progress_file = Path(f'./cleanLyrics/{n:02d}-progress-base-uncased-78728.txt')\n",
    "\n",
    "progress = list()\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, 'r') as pf:\n",
    "        for line in pf:\n",
    "            progress.append(str(line).replace('\\n', ''))\n",
    "else:\n",
    "    with open(progress_file, 'a') as pf:\n",
    "        pass\n",
    "\n",
    "print(len(progress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2a6ad26d214c08a68487da04f91487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78728), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean text and write to dev, test, and train files\n",
    "i = 0\n",
    "for rlf in tqdm.tqdm_notebook(raw_lyrics_files):\n",
    "    if str(rlf) not in progress:\n",
    "        formatted_song = f.format_lyrics(rlf)\n",
    "\n",
    "        if formatted_song:\n",
    "            i += 1\n",
    "\n",
    "            # 5% to dev\n",
    "            if i % 20 == 0:\n",
    "                with open(dev_file, 'a') as df:\n",
    "                    for section in formatted_song['sections']:\n",
    "                        for l in section:\n",
    "                            df.write(f'{l}\\n')\n",
    "                        df.write('\\n')  # Double newline between sections\n",
    "\n",
    "            # 5% to test\n",
    "            elif i % 20 == 1:\n",
    "                with open(test_file, 'a') as tef:\n",
    "                    for section in formatted_song['sections']:\n",
    "                        for l in section:\n",
    "                            tef.write(f'{l}\\n')\n",
    "                        tef.write('\\n')\n",
    "\n",
    "            # 90% to train\n",
    "            else:\n",
    "                with open(train_file, 'a') as trf:\n",
    "                    for section in formatted_song['sections']:\n",
    "                        for l in section:\n",
    "                            trf.write(f'{l}\\n')\n",
    "                        trf.write('\\n')  \n",
    "\n",
    "        # Record progress\n",
    "        progress.append(str(rlf))\n",
    "        with open(progress_file, 'a') as pf:\n",
    "            pf.write(f'{rlf}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "bt = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3d9380ceee409cb9ce8baa0ac84b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4149686), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4149687\n"
     ]
    }
   ],
   "source": [
    "line_lens = list()\n",
    "with open(train_file, 'r') as lf:\n",
    "    for i, line in enumerate(lf):\n",
    "        pass\n",
    "\n",
    "with open(train_file, 'r') as lf:\n",
    "    for line in tqdm.tqdm_notebook(lf, total=i):\n",
    "        tokens = bt.tokenize(line)\n",
    "        line_lens.append(len(tokens))\n",
    "print(len(line_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_lens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 1054    Min: 0    %>64: 0.06665562968966093\n"
     ]
    }
   ],
   "source": [
    "print(f'Max: {max(line_lens)}    Min: {min(line_lens)}    %>64: {100*sum([1 for l in line_lens if l > 64])/len(line_lens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Max: {max(line_lens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put lyrics in AllLyrics.sqlite\n",
    "for i, rlf in enumerate(raw_lyrics_files):\n",
    "    formatted_song = f.format_lyrics(rlf)\n",
    "\n",
    "    artist = formatted_song['artist']\n",
    "    if artist not in aly:\n",
    "        aly[artist] = list()\n",
    "    if len(aly[artist]) == 0 or formatted_song['title'] not in aly[artist][:]['title']:\n",
    "        aly[artist].append(formatted_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG",
   "language": "python",
   "name": "gg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
